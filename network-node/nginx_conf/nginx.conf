worker_processes 1;

events {
    worker_connections 4096;
}

http {
    log_format format_with_cache_status '$remote_addr - $remote_user [$time_local] '
                       '"$request" $status x-cache-status=$upstream_cache_status $bytes_sent '
                       '"$http_referer" "$http_user_agent" "$gzip_ratio"';
    access_log /usr/local/openresty/logs/access.log format_with_cache_status;

    # A value of 0 disables client upload size check on the nginx proxy layer, and shifts the responsibility
    # back to the app
    client_max_body_size 0;
    lua_package_path "/usr/local/openresty/conf/?.lua;;";

    # Inactive = how long an item can remain in the cache without being accessed
    # If inactive period passes, content WILL BE DELETED from the cache by the cache
    # manager, regardless whether or not it has expired.
    # https://www.nginx.com/blog/nginx-caching-guide#How-to-Set-Up-and-Configure-Basic-Caching
    proxy_cache_path /usr/local/openresty/cache levels=1:2 keys_zone=cidcache:1000m
					max_size=4g inactive=12h use_temp_path=off;
    proxy_read_timeout 3600; # 1 hour in seconds

    server {
        listen 4000;

        # Match the paths /ipfs/<cid: string> and /content/<cid: string>.
        # If present in cache, serve. Else, hit upstream server + update cache + serve.
        # http://nginx.org/en/docs/http/ngx_http_core_module.html#location
        location ~ (/ipfs/|/content/) {
            proxy_cache cidcache;
            proxy_pass http://127.0.0.1:3000;

            # Set client IP
            proxy_set_header X-Forwarded-For $remote_addr;

            # proxy_cache_use_stale + proxy_cache_background_update -> deliver stale content when client requests
            # an item that is expired or in the process of being updated from origin server
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;

            # Cache only responses with status code = 200 for some duration before considered stale.
            # Stale implies content will be fetched from the upstream server. Stale content WILL NOT
            # BE REMOVED from the cache.
            proxy_cache_valid 200 12h;
            
            # When enabled, only one request at a time will be allowed to populate a new cache element
            # Other requests of the same cache element will either wait for a response to appear in the cache
            # or the cache lock for this element to be released
            proxy_cache_lock on;
            # If the last request passed to the proxied server for populating a new cache element has not 
            # completed for the specified time, one more request may be passed to the proxied server
            proxy_cache_lock_age 1s;
            # When 2s passes, the request will be passed to the proxied server, however, the response will not be cached
            proxy_cache_lock_timeout 2s;

            # Bypass cache with bypasscache=true query string and save new response to proxy cache
            proxy_cache_bypass $arg_bypasscache;

            # Add header to indicate the status of the cache with this request
            add_header X-Cache-Status $upstream_cache_status always;
        }

        # Pass all other requests to upstream server
        location / {
            proxy_pass http://127.0.0.1:3000;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}